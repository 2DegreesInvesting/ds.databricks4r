---
output: github_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Databricks for RStudio users

The goal of this series is to help R users understand if and how they can do in
Databricks the things they commonly do in RStudio. I'll point to some frictions
I see as an RStudio user new to Databricks.

At the end of this series you'll be able to do things like this:

* Add folders, .R files and notebooks to your Workspace.
* Work with Git and GitHub.
* Create a spark dataframe from a table in the Databricks Catalog.
* Run jobs.
* Create a cluster with RStudio installed in it.

## Who is the audience?

Analysts used to RStudio.

## Why is this important?

Databricks is like a racing car. It's great for racing but for an RStudio user
it may not be a confortable everyday car. Understanding what you can and
shouldn't do with Databricks will save you time and frustration.

## Workspace

* Add a folder, file.R and notebook with markdown
```
%md 
# hi
```

```
%r
print("hi")
```
* Connect to a running cluster
* In the file.R note the Output and Terminal tabs

**Friction**

* Editing text is limited.
* Only a few file formats are supported. Try a shell_script.sh
* The working directory seems to vary with the language:
```
%r
getwd()
[1] "/tmp/Rserv/conn4266"
```

```
%sh
Rscript -e "getwd()"
[1] "/databricks/driver"
```

```
%python
os.getcwd()
[1] "/databricks/driver"
```

## Repos

* Cone https://github.com/2DegreesInvesting/ds.databricks4r
* Change README on a new branch.
* Commit and push.
* Create a PR on GitHub.

**Friction**

* Git operations from the UI are basic, and from the Terminal may be impossible:
```bash
/Workspace/Repos/mauro@2degrees-investing.org/ds.databricks4r# git status
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
```

## Catalog

* Read a (parquet?) file from the Databricks Catalog.

<image width=700 src=https://github.com/2DegreesInvesting/ds.databricks4r/assets/5856545/a632de43-c83e-41be-9577-3b7c89019156>

```r
path <- "raw.default.country"
data <- SparkR::tableToDF("raw.default.country")
data
```

* Read a .csv file from "disk".

```r
path <- "/databricks-datasets/Rdatasets/data-001/datasets.csv"
data <- readr::read_csv(path)
data
```

* Read a .csv file from Azure storage (works outside Databricks).

<img width=700 src=https://github.com/2DegreesInvesting/tiltIndicator/assets/5856545/f8aa5a3e-ebff-48e6-87eb-889f477c8831>

```r
library(AzureStor)

# usethis::edit_r_environ()
# User delegation key with all 10 permissions
# AZURE_CONTAINER_SAS_TEST_MAURO="paste the SAS token here"
url <- "https://storagetiltdevelop.blob.core.windows.net/test-mauro"
sas <- Sys.getenv("AZURE_CONTAINER_SAS_TEST_MAURO")
container <- blob_container(url, sas = sas)

storage_read_csv(container, "data/iris.csv")
```

**Friction**

* SparkR is no longer on CRAN [(archived in 2021 for lack of maintenance)](https://cran.r-project.org/web/packages/SparkR/index.html).
* The [sparklyr package](https://spark.rstudio.com/deployment/databricks-cluster.html) seem like a good alternative but I failed to use it.
* Code written for R dataframes may not work for [spark dataframes](https://spark.apache.org/docs/latest/sparkr.html#sparkdataframe-operations).

## Workflows

* Create a workflow, run it and view it.

**Friction**

* There is no obvious way to turn the workflow into text and track it with Git.

## Compute

* Create a new cluster with RStudio (use Runtime ML, dissable auto termination).
* Setup RStudio: Compute > click on cluster > Apps > Set up RStudio.

**Friction**

* RStudio lacks `sudo`.
* RStudio requires no auto-termination.
* Starting a cluster takes minutes.
* RStudio lacks direct access to the Databricks Catalog.
* RStudio won't persist when restarting the cluster.

## Resources

* YouTube [playlist](https://bit.ly/ds-incubator-videos).
* [What is Databricks](https://docs.databricks.com/en/introduction/index.html).

## Thanks

Tanks Sven for patiently answering my questions.
